{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bihjmZ8WuMdj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Helper function for parameter initialization\n",
        "def initialize_parameters(n_x):\n",
        "    \"\"\"\n",
        "    Initializes parameters W and b for a single-layer neural network (perceptron).\n",
        "\n",
        "    Arguments:\n",
        "    n_x -- size of the input layer (number of features, in this case 2)\n",
        "\n",
        "    Returns:\n",
        "    parameters -- dictionary containing W and b\n",
        "    \"\"\"\n",
        "    np.random.seed(1)  # Seed for reproducibility\n",
        "\n",
        "    # Initialize weights and bias\n",
        "    W = np.random.randn(1, n_x) * 0.01  # Small random values for W\n",
        "    b = np.zeros((1, 1))                 # Bias initialized to zero\n",
        "\n",
        "    parameters = {\"W\": W, \"b\": b}\n",
        "    return parameters\n",
        "\n",
        "# Forward Propagation\n",
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Perform forward propagation for a single-layer perceptron.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input data of shape (n_x, m), where n_x is the input feature dimension (2), m is the number of examples\n",
        "    parameters -- dictionary containing \"W\" and \"b\"\n",
        "\n",
        "    Returns:\n",
        "    Y_hat -- predicted output of shape (1, m)\n",
        "    \"\"\"\n",
        "    W = parameters[\"W\"]\n",
        "    b = parameters[\"b\"]\n",
        "\n",
        "    # Calculate the linear part of the perceptron\n",
        "    Z = np.dot(W, X) + b\n",
        "    Y_hat = Z\n",
        "\n",
        "    return Y_hat\n",
        "\n",
        "# Compute Cost Function\n",
        "def compute_cost(Y_hat, Y):\n",
        "    \"\"\"\n",
        "    Computes the sum of squared errors cost function.\n",
        "\n",
        "    Arguments:\n",
        "    Y_hat -- predicted output of the neural network, shape (1, m)\n",
        "    Y -- true labels vector, shape (1, m)\n",
        "\n",
        "    Returns:\n",
        "    cost -- sum of squared errors scaled by 1/(2*m)\n",
        "    \"\"\"\n",
        "    m = Y.shape[1]  # Number of training examples\n",
        "    cost = np.sum((Y_hat - Y) ** 2) / (2 * m)  # Sum of squared errors cost function\n",
        "    return cost\n",
        "\n",
        "# Backward Propagation and Parameters Update (Gradient Descent)\n",
        "def train_nn(parameters, Y_hat, X, Y, learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Updates parameters using gradient descent.\n",
        "\n",
        "    Arguments:\n",
        "    parameters -- dictionary containing \"W\" and \"b\"\n",
        "    Y_hat -- predicted output of the neural network, shape (1, m)\n",
        "    X -- input data, shape (n_x, m)\n",
        "    Y -- true labels, shape (1, m)\n",
        "    learning_rate -- learning rate for gradient descent\n",
        "\n",
        "    Returns:\n",
        "    parameters -- updated dictionary containing new values of \"W\" and \"b\"\n",
        "    \"\"\"\n",
        "    m = Y.shape[1]  # Number of training examples\n",
        "    W = parameters[\"W\"]\n",
        "    b = parameters[\"b\"]\n",
        "\n",
        "    # Compute gradients\n",
        "    dW = (1/m) * np.dot(Y_hat - Y, X.T)\n",
        "    db = (1/m) * np.sum(Y_hat - Y)\n",
        "\n",
        "    # Update parameters using gradient descent\n",
        "    W = W - learning_rate * dW\n",
        "    b = b - learning_rate * db\n",
        "\n",
        "    # Update the parameters dictionary\n",
        "    parameters = {\"W\": W, \"b\": b}\n",
        "    return parameters\n",
        "\n",
        "# Neural Network Model\n",
        "def nn_model(X, Y, num_iterations=1000, print_cost=False):\n",
        "    \"\"\"\n",
        "    Trains the neural network model using perceptron for a specified number of iterations.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input data of shape (n_x, m)\n",
        "    Y -- true labels of shape (1, m)\n",
        "    num_iterations -- number of iterations for training\n",
        "    print_cost -- if True, prints the cost every 100 iterations\n",
        "\n",
        "    Returns:\n",
        "    parameters -- learned parameters (W and b)\n",
        "    \"\"\"\n",
        "    n_x = X.shape[0]  # Size of the input layer (number of features)\n",
        "\n",
        "    # Initialize parameters\n",
        "    parameters = initialize_parameters(n_x)\n",
        "\n",
        "    # Training loop\n",
        "    for i in range(num_iterations):\n",
        "\n",
        "        # Forward Propagation\n",
        "        Y_hat = forward_propagation(X, parameters)\n",
        "\n",
        "        # Compute cost\n",
        "        cost = compute_cost(Y_hat, Y)\n",
        "\n",
        "        # Backward Propagation (Gradient Descent)\n",
        "        parameters = train_nn(parameters, Y_hat, X, Y)\n",
        "\n",
        "        # Print cost every 100 iterations\n",
        "        if print_cost and i % 100 == 0:\n",
        "            print(f\"Cost after iteration {i}: {cost:.6f}\")\n",
        "\n",
        "    return parameters\n",
        "\n",
        "# Prediction Function\n",
        "def predict(X, parameters):\n",
        "    \"\"\"\n",
        "    Uses the learned parameters to predict outputs for new data.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input data of shape (n_x, m)\n",
        "    parameters -- learned parameters\n",
        "\n",
        "    Returns:\n",
        "    predictions -- predicted outputs, shape (1, m)\n",
        "    \"\"\"\n",
        "    Y_hat = forward_propagation(X, parameters)\n",
        "    return Y_hat\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Example dataset: XOR dataset\n",
        "    X_train = np.array([[0, 0, 1, 1], [0, 1, 0, 1]])  # Inputs (2 features)\n",
        "    Y_train = np.array([[0, 1, 1, 0]])  # XOR Outputs (true labels)\n",
        "\n",
        "    # Train the perceptron model\n",
        "    parameters = nn_model(X_train, Y_train, num_iterations=1000, print_cost=True)\n",
        "\n",
        "    # Make predictions on the training set\n",
        "    predictions = predict(X_train, parameters)\n",
        "\n",
        "    # Show the predictions\n",
        "    print(\"\\nPredictions:\")\n",
        "    print(predictions)\n",
        "\n",
        "    print(\"\\nActual Labels:\")\n",
        "    print(Y_train)"
      ]
    }
  ]
}